{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImagePoemMatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input: 이미지키워드 토크나이징 데이터 (json) + 시 토크나이징 데이터 (json)\n",
    "- output: 이미지 키워드와 시 키워드의 코사인 유사도가 가장 높은 이미지와 시 매칭 (json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 필요한 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import fasttext\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 필요한 데이터 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 토픽 모음\n",
    "# 'restaurant', 'tower'\n",
    "image_topic = ['beach', 'cave', 'island', 'lake', 'mountain', 'amusement', 'palace', 'park']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 키워드 토크나이징 데이터 저장 리스트\n",
    "image_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 키워드 토크나이징 데이터 로드\n",
    "for topic in image_topic:\n",
    "    with open('../data/{topic}_token.json'.format(topic=topic), 'rb') as f:\n",
    "        image_tokens.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시 키워드 토크나이징 데이터 로드\n",
    "with open('../data/poem_token.pkl', 'rb') as f:\n",
    "    poem_token = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. 테스트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시 토큰화\n",
    "with open('./data/final_poem_token.pkl', 'rb') as f:\n",
    "    poem_token = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [[성실/NNG_, 하/XSA_, ㅁ/ETN_, 이나/JC_, 근면/NNG_, 하/...\n",
       "1        [[무모/NNG_, 하/XSA_, 게/EC_, 달리/VV_, ㄴ다/EC_, 첨/NN...\n",
       "2        [[건/VV_, 지/NNG_, 려/EC_, 하/VX_, 니/EC_, 가시/NNG_,...\n",
       "3        [[하/VV_, 여야/EC_, 하/VV_, 여야/EC_, 나오/VV_, 너라/EC_...\n",
       "4        [[파도/NNG_, 처럼/JKB_, 울렁대/VV_, 는/ETM_, 변덕/NNG_, ...\n",
       "5        [[돌아보/VV_, 면/EC_, 언제나/MAG_, 혼자/NNG_, 이/VCP_, 었...\n",
       "6        [[아무것/NNG_, 도/JX_, 보이/VV_, 지/EC_, 않/VX_, 습니다/E...\n",
       "7        [[그/NP_, 의/JKG_, 몸/NNG_, 에/JKB_, ㄴ/JX_, 기생충/NN...\n",
       "8        [[내/NP_, 가/JKS_, 사랑/NNG_, 하/XSV_, 였/EP_, 기/ETN...\n",
       "9        [[나/NP_, ㄴ/JX_, 너/NP_, 에게/JKB_, 비/NNG_, 오/VV_,...\n",
       "10       [[네/NNG_, 온/NNP_, 사/NNG_, 인/NNP_, 은/JX_, 섹소폰/N...\n",
       "11       [[끈/NNG_], [조각/NNG_, 조각/NNG_, 을/JKO_, 잇/VV_, 어...\n",
       "12       [[기억/NNG_, 은/JX_, 나/VV_, 지/EC_, 않/VX_, 습니다언/EC...\n",
       "13       [[햇빛/NNG_, 맑/VA_, 아/EC_, 좋/VA_, 은/ETM_, 날/NNG_...\n",
       "14       [[비/NNG_, 가/JKS_, 오/VV_, ㄴ다/EC_], [오누나/NNG_, 오...\n",
       "15       [[부러/MAG_, 지/VV_, ㄴ/ETM_, 뼈/NNG_, 들/XSN_, 은/JX...\n",
       "16       [[작/VA_, 은/ETM_, 나무/NNG_, 들/XSN_, 은/JX_, 겨울/NN...\n",
       "17       [[박/NNP_, 현/MM_, 자년/NNG_, 월/NNG_, 희망/NNG_, 이/J...\n",
       "18       [[잠깐/NNG_, 만/JX_, 멈추/VV_, 어서/EC_, 그때/NNG_, 피/V...\n",
       "19       [[오늘/NNG_, 은/JX_, 너무/MAG_, 잘/MAG_, 알/VV_, 기/ET...\n",
       "20       [[어둠/NNG_, 속/NNG_, 에/JKB_, 잠들/VV_, ㄴ/ETM_, 나/N...\n",
       "21       [[교만/NNG_, 하/XSV_, 지/EC_, 는/JX_, 말/VX_, 아야지요/E...\n",
       "22       [[행/NNG_, 로/JKB_], [기침/NNG_, 이/VCP_, 나/VV_, ㄴ다...\n",
       "23       [[앙금/NNG_, 처럼/JKB_, 가/VV_, 라/NNG_, 앉/VV_, 는/ET...\n",
       "24       [[난장판/NNG_, 되/XSV_, ㄴ/ETM_, 수라장/NNG_, 이/VCP_, ...\n",
       "25       [[말/NNG_, 로써/JKB_, 말/NNG_, 하/XSV_, 려/EC_, 말/VX...\n",
       "26       [[눈/NNG_, 은/JX_, 내리/VV_, 네/XSN_, 오/VV_, 아서/EC_...\n",
       "27       [[괜시리/MAG_, 돌/VV_, 아/EC_, 오/VX_, 았/EP_, 어요/EC_...\n",
       "28       [[화로/NNG_], [거죽/NNG_, 에/JKB_, 이오/VV_, 아/EC_, 닿...\n",
       "29       [[첫눈/NNG_, 오/VV_, 는/ETM_, 날/NNG_], [차창/NNG_, 위...\n",
       "                               ...                        \n",
       "74524    [[호젖/NNG_, 하/XSV_, ㄴ/ETM_, 오솔길/NNG_], [낙엽/NNG_...\n",
       "74525    [[구구/NNG_, 비둘기/NNG_, 는/JX_], [이제/MAG_, 밤/NNG_,...\n",
       "74526    [[송곳/NNG_, 을/JKO_, 구부리/VV_, 어/EC_], [천공/NNG_, ...\n",
       "74527    [[오늘/NNG_, 도/JX_, 그만/MAG_], [오늘/NNG_, 또/MAG_, ...\n",
       "74528    [[그냥/MAG_, 지나가/VV_, ㄴ다/EC_], [순순히/MAG_, 털/VV_,...\n",
       "74529    [[길/NNG_, 이/JKC_, 아니/VCN_, 라/EC_], [빛/NNG_, 이/...\n",
       "74530    [[멀리/MAG_, 있/VV_, 어도/EC_], [소름/NNG_, 이/JKS_, 돋...\n",
       "74531    [[사라지/VV_, 어/EC_, 가/VX_, ㄴ다/EC_], [흩어지/VV_, 어/...\n",
       "74532    [[아니/IC_, 혼자/NNG_, 서/JKB_], [지키/VV_, 려는/ETM_, ...\n",
       "74533    [[불볕/NNG_, 더위/NNG_], [태양/NNG_, 이/JKS_, 싫/VA_, ...\n",
       "74534    [[밤/NNG_, 의/JKG_, 어둠/NNG_], [니/NP_, 마음/NNG_, 의...\n",
       "74535    [[실컷/MAG_, 울/VV_, 으렴/EC_], [맘껏/MAG_, 소리/NNG_, ...\n",
       "74536    [[환상/NNG_, 적/XSN_, 이/VCP_, 네/NNP_], [채석장/NNG_,...\n",
       "74537    [[시/NNG_, 의/JKG_, 숲/NNG_, 에서/JKB_], [기울이/VV_, ...\n",
       "74538    [[깨물/VV_, 어/EC_, 보/VX_, ㄹ까/EC_], [빠지/VV_, 어/EC...\n",
       "74539    [[눈물/NNG_, 이/VCP_, 었/EP_, 네/EC_], [눈물/NNG_, 이/...\n",
       "74540    [[앞/NNG_, 물결/NNG_, 따르/VV_, 아/EC_], [뒷배/NNG_, 에...\n",
       "74541    [[이슬/NNG_, 젖/VV_, 은/ETM_], [한줌/NNG_, 햇살/NNG_],...\n",
       "74542    [[오/NR_, 월/NNG_, 의/JKG_], [초록/NNG_], [초록/NNG_]...\n",
       "74543    [[작/VA_, 은/ETM_, 설날/NNG_], [불빛/NNG_, 하나/NR_], ...\n",
       "74544    [[가부좌/NNG_, 튼/NP_, 채/NNB_], [웅얼웅얼/MAG_, 웅얼웅얼/M...\n",
       "74545    [[알로하/NNG_, 오/NNG_, 에/JKB_], [None], [None], [...\n",
       "74546    [[까치집/NNG_, 보/VV_, 면/EC_], [생각/NNG_, 납/NNG_, 니...\n",
       "74547    [[임보/NNG_], [오르/VV_, 는/ETM_], [골짝/MAG_], [오리나무...\n",
       "74548    [[한/MM_, 줄/NNB_, 사연/NNG_], [권/NNP_, 갑/NNG_, 하/...\n",
       "74549    [[손톱/NNG_, 발톱/NNG_], [연/NNP_, 지/NNG_, 곤지/NNG_]...\n",
       "74550    [[자격/NNG_, 없/VA_, 다/EC_], [미련/NNG_, 없/VA_, 다/E...\n",
       "74551    [[None], [한/MM_, 시간/NNG_, 씩/MAG_], [십/NR_, 년/N...\n",
       "74552    [[뒤뚱/MAG_, 뛰/VV_, 뚱/MAG_], [새끼/NNG_, 오리/NNG_, ...\n",
       "74553    [[취하/VV_, 느니라/EC_], [채우/VV_, 느니라/EC_], [취하/VV_...\n",
       "Name: new_contents, Length: 74554, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poem_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 코드\n",
    "with open('./data/beach_token.json', 'rb') as f:\n",
    "    beach_keyword_token = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'beach',\n",
       " 'img_name': '1',\n",
       " 'keyword': [['바닷가/NNG_'],\n",
       "  ['모래/NNG_'],\n",
       "  ['바다/NNG_'],\n",
       "  ['물/NNG_', '이/JKS_', '몸/NNG_'],\n",
       "  ['여름/NNG_'],\n",
       "  ['대양/NNG_'],\n",
       "  ['해/NNG_'],\n",
       "  ['재미/NNG_'],\n",
       "  ['분명히/MAG_'],\n",
       "  ['레저/NNG_', '(/SS_', '시간/NNG_', '꺼/VV_', '짐/NNG_', ')/SS_'],\n",
       "  ['여행/NNG_'],\n",
       "  ['휴가/NNG_'],\n",
       "  ['사랑/NNG_'],\n",
       "  ['아이/NNG_'],\n",
       "  ['밀리/VV_', '어/EC_', '오/VX_', '는/ETM_', '파도/NNG_'],\n",
       "  ['자연/NNG_'],\n",
       "  ['연안/NNG_'],\n",
       "  ['천국/NNG_'],\n",
       "  ['자유/NNG_', '(/SS_', '상태/NNP_', ')/SS_'],\n",
       "  ['남성/NNG_'],\n",
       "  ['ᄉ/NNG_', 'ᅩᆨ초해수ᄋ/SH_', 'ᅭᆨ자/NNP_', 'ᆼ/SH_'],\n",
       "  ['ᄀ/NNG_', 'ᅡ족/SH_', '여해/NNP_', 'ᆼ/SH_'],\n",
       "  ['ᄀ/NNG_', 'ᅧ울/SH_', '바ᄃ/NNP_', 'ᅡ/SH_'],\n",
       "  ['ᄉ/NNG_', 'ᅩᆨ초해수ᄋ/SH_', 'ᅭᆨ자/NNP_', 'ᆼ/SH_'],\n",
       "  ['ᄀ/NNG_', 'ᅡ족/SH_', '여해/NNP_', 'ᆼ/SH_'],\n",
       "  ['ᄀ/NNG_', 'ᅧ울/SH_', '바ᄃ/NNP_', 'ᅡ/SH_'],\n",
       "  ['ᄉ/NNG_', 'ᅩᆨ초해수ᄋ/SH_', 'ᅭᆨ자/NNP_', 'ᆼ/SH_'],\n",
       "  ['ᄀ/NNG_', 'ᅡ족/SH_', '여해/NNP_', 'ᆼ/SH_'],\n",
       "  ['ᄀ/NNG_', 'ᅧ울/SH_', '바ᄃ/NNP_', 'ᅡ/SH_'],\n",
       "  ['ᄇ/NNG_',\n",
       "   'ᅡ/SH_',\n",
       "   'ᄃ/SL_',\n",
       "   'ᅡᄂ/SH_',\n",
       "   'ᅳ/NNP_',\n",
       "   'ᆫ/SH_',\n",
       "   '늘/SH_',\n",
       "   '좋다/SH_',\n",
       "   './SF_']]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 모양 확인\n",
    "beach_keyword_token[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터에서 명사인 키워드만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_none(x):\n",
    "    d = []\n",
    "    for j in tqdm(x):\n",
    "        c = []\n",
    "        for i in j:\n",
    "            if i == None:\n",
    "                pass\n",
    "            else:\n",
    "                c.append(i)\n",
    "        d.append(c)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_noun_va(x):\n",
    "    new_a = []\n",
    "    for j in tqdm(x):\n",
    "        aa = []\n",
    "        for i in j:   \n",
    "            if 'NNG' in i:\n",
    "                aa.append(i)\n",
    "        new_a.append(aa)\n",
    "    return new_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명사/NN => 명사\n",
    "def only_words(x):\n",
    "    a = []\n",
    "    for i in tqdm(x):\n",
    "        b = []\n",
    "        for j in i:\n",
    "            b.append(j.split('/')[0])\n",
    "        a.append(b)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun_keyword(img_data):\n",
    "    key_tok = []\n",
    "    for i in range(len(img_data)):\n",
    "        key_tok.append(img_data[i]['keyword'])\n",
    "    flatten_key_tok = []\n",
    "    for i in key_tok:\n",
    "        flatten_key_tok.append([y for x in i for y in x])\n",
    "    noun_kwd = select_noun_va(del_none(flatten_key_tok))\n",
    "    for i in tqdm(range(len(img_data))):\n",
    "        img_data[i]['keyword'] = 0\n",
    "        img_data[i]['keyword'] = list(set(noun_kwd[i]))\n",
    "    return img_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b6e51731917e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimage_token\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimage_tokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mimage_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_noun_keyword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "for image_token in image_tokens:\n",
    "    image_token = get_noun_keyword(image_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1-1. 테스트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 66852.15it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 66841.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 125319.07it/s]\n"
     ]
    }
   ],
   "source": [
    "beach_keyword_token = get_noun_keyword(beach_keyword_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'beach',\n",
       " 'img_name': '1',\n",
       " 'keyword': ['사랑/NNG_',\n",
       "  '자연/NNG_',\n",
       "  '몸/NNG_',\n",
       "  'ᄇ/NNG_',\n",
       "  '바다/NNG_',\n",
       "  '레저/NNG_',\n",
       "  '아이/NNG_',\n",
       "  '시간/NNG_',\n",
       "  '남성/NNG_',\n",
       "  '해/NNG_',\n",
       "  '물/NNG_',\n",
       "  '모래/NNG_',\n",
       "  'ᄉ/NNG_',\n",
       "  '천국/NNG_',\n",
       "  '여행/NNG_',\n",
       "  '짐/NNG_',\n",
       "  '바닷가/NNG_',\n",
       "  '파도/NNG_',\n",
       "  '여름/NNG_',\n",
       "  '대양/NNG_',\n",
       "  'ᄀ/NNG_',\n",
       "  '휴가/NNG_',\n",
       "  '연안/NNG_',\n",
       "  '자유/NNG_',\n",
       "  '재미/NNG_']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beach_keyword_token[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. 시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "명사 토큰이 없을 때 해당 시를 버리겠다는 의미로 'ㄱ'을 넣어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun_poem(poem_data):\n",
    "    flatten_poem_tok = []\n",
    "    for i in poem_data:\n",
    "        flatten_poem_tok.append([y for x in i for y in x])\n",
    "    noun_poem = select_noun_va(del_none(flatten_poem_tok))\n",
    "    # 시의 경우, 명사 토큰이 없는 경우, 임의로 'ㄱ'을 넣어준다. 해당 시를 버리겠다는 것\n",
    "    for i in range(len(noun_poem)):\n",
    "        if len(noun_poem[i]) == 0:\n",
    "            noun_poem[i] = ['ㄱ']       \n",
    "    return noun_poem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 74554/74554 [00:01<00:00, 70286.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 74554/74554 [00:01<00:00, 60568.15it/s]\n"
     ]
    }
   ],
   "source": [
    "noun_poem = get_noun_poem(poem_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(noun_poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['성실/NNG_',\n",
       " '근면/NNG_',\n",
       " '도/NNG_',\n",
       " '로/NNG_',\n",
       " '정직/NNG_',\n",
       " '삶/NNG_',\n",
       " '사랑/NNG_',\n",
       " '때/NNG_',\n",
       " '때/NNG_',\n",
       " '답/NNG_',\n",
       " '때/NNG_',\n",
       " '작은사람/NNG_',\n",
       " '사랑/NNG_',\n",
       " '안/NNG_',\n",
       " '키/NNG_',\n",
       " '사람/NNG_',\n",
       " '숲/NNG_']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_poem[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여기!) fasttext에 들어갈 onlyword 형태의 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onlyword_keyword(img_data):\n",
    "    key_tok = []\n",
    "    for i in range(len(img_data)):\n",
    "        key_tok.append(img_data[i]['keyword'])\n",
    "    flatten_key_tok = []\n",
    "    for i in key_tok:\n",
    "        flatten_key_tok.append([y for x in i for y in x])\n",
    "    noun_kwd = only_words(select_noun_va(del_none(flatten_key_tok))) # only_words 추가\n",
    "    for i in tqdm(range(len(img_data))):\n",
    "        img_data[i]['keyword'] = 0\n",
    "        img_data[i]['keyword'] = list(set(noun_kwd[i]))\n",
    "    return img_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이게 맞나???\n",
    "image_words = []\n",
    "for image_token in image_tokens:\n",
    "    image_word = []\n",
    "    image_word = get_onlyword_keyword(image_token)\n",
    "    image_words.append(image_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 58981.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 77130.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 83550.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 200655.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# get_noun_keyword 다음에 수행하면 x, 데이터 다시 불러오던지, only_words만 따로 적용시키던지\n",
    "beach_onlyword = get_onlyword_keyword(beach_keyword_token)\n",
    "# beach_keyword_token 도 변해 뒤에가 사라져"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 74554/74554 [00:04<00:00, 17190.91it/s]\n"
     ]
    }
   ],
   "source": [
    "poem_onlyword = only_words(noun_poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'beach',\n",
       " 'img_name': '1',\n",
       " 'keyword': ['휴가',\n",
       "  '아이',\n",
       "  '대양',\n",
       "  'ᄇ',\n",
       "  'ᄉ',\n",
       "  '짐',\n",
       "  '천국',\n",
       "  '연안',\n",
       "  '레저',\n",
       "  '바다',\n",
       "  '여행',\n",
       "  '자연',\n",
       "  '몸',\n",
       "  '사랑',\n",
       "  'ᄀ',\n",
       "  '물',\n",
       "  '바닷가',\n",
       "  '재미',\n",
       "  '여름',\n",
       "  '모래',\n",
       "  '해',\n",
       "  '파도',\n",
       "  '시간',\n",
       "  '자유',\n",
       "  '남성']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beach_onlyword[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['성실',\n",
       " '근면',\n",
       " '도',\n",
       " '로',\n",
       " '정직',\n",
       " '삶',\n",
       " '사랑',\n",
       " '때',\n",
       " '때',\n",
       " '답',\n",
       " '때',\n",
       " '작은사람',\n",
       " '사랑',\n",
       " '안',\n",
       " '키',\n",
       " '사람',\n",
       " '숲']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poem_onlyword[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. fasttext 모델로 word vector 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트 코드\n",
    "model = fasttext.load_model('wiki.ko.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.load_model('../model/wiki.ko/wiki.ko.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_dimension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. 이미지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지 각 키워드의 명사 토큰을 300차원으로 임베딩한다.\n",
    "- 이미지를 대표하는 하나의 벡터로 만든다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 token을 word로 바꿔야"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_img(image_token):\n",
    "    tot = []\n",
    "    for i in tqdm(range(len(image_token))):\n",
    "        sen = []\n",
    "        for j in range(len(image_token[i]['keyword'])):\n",
    "            sen.append(model.get_word_vector(image_token[i]['keyword'][j]))\n",
    "        tot.append(sen)\n",
    "    return tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_vector_image_keyword = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_token in tqdm(image_tokens):\n",
    "    tot = embedding_img(image_token)\n",
    "    new_tot = np.array([np.array(i) for i in tot])\n",
    "    new_tot_samplesum = [ np.sum(i, axis=0) for i in new_tot]\n",
    "    vector_keyword = np.array(new_tot_samplesum)\n",
    "    embeded_vector_image_keyword.append(vector_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 300차원 확인\n",
    "embeded_vector_image_keyword[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [embeded_vector_keyword]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-1. 테스트코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1144.72it/s]\n"
     ]
    }
   ],
   "source": [
    "tot = embedding_img(beach_onlyword)\n",
    "new_tot = np.array([np.array(i) for i in tot])\n",
    "new_tot_samplesum = [ np.sum(i, axis=0) for i in new_tot]\n",
    "vector_keyword = np.array(new_tot_samplesum)\n",
    "embeded_vector_image_keyword.append(vector_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 300차원 확인\n",
    "embeded_vector_image_keyword[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. 시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 단어를 300차원으로 임베딩한다.\n",
    "- 시를 대표하는 하나의 벡터로 만든다 (시 단위로 임베딩한 벡터들을 더함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_poem(noun_poem):\n",
    "    total = []\n",
    "    for i in tqdm(range(len(noun_poem))):\n",
    "        sen = []\n",
    "        for j in range(len(noun_poem[i])):\n",
    "            sen.append(model.get_word_vector(noun_poem[i][j]))\n",
    "        total.append(sen)\n",
    "    new_total = np.array([np.array(i) for i in total])\n",
    "    new_total_samplesum = [ np.sum(i, axis=0) for i in new_total]\n",
    "    new_total_samplesum = np.array(new_total_samplesum)\n",
    "    return new_total_samplesum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 74554/74554 [00:47<00:00, 1572.04it/s]\n"
     ]
    }
   ],
   "source": [
    "embeded_vector_poem = embedding_poem(poem_onlyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 300차원 확인\n",
    "embeded_vector_poem[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeded_vector_poem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 코사인 유사도 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- keyword_vector로 이미지와 가장 걸맞는(a.k.a 가장 유사도가 높은) poem_vector를 구하고, 그 시의 index를 append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.sqrt(np.dot(x, x)) * np.sqrt(np.dot(y, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_index(vector_keyword, vector_poem):\n",
    "    scores = []\n",
    "    for i in range(len(vector_poem)):\n",
    "        score = cosine_similarity(vector_keyword, vector_poem[i])\n",
    "        scores.append(score)\n",
    "    index = scores.index(max(scores))\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for embeded_vector_keyword in embeded_vector_image_keyword:\n",
    "    index_list = []\n",
    "    for i in range(len(embeded_vector_keyword)):\n",
    "        index = return_index(embeded_vector_keyword[i], embeded_vector_poem)\n",
    "        index_list.append(index)\n",
    "    matched_list.append(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matched_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(matched_list[0]))  # 매칭된 시 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델을 위한 json 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poem_token 형태 그대로네? (noun만 아니고) 시 전체 데이터!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'beach',\n",
       " 'img_name': '1',\n",
       " 'keyword': ['휴가',\n",
       "  '아이',\n",
       "  '대양',\n",
       "  'ᄇ',\n",
       "  'ᄉ',\n",
       "  '짐',\n",
       "  '천국',\n",
       "  '연안',\n",
       "  '레저',\n",
       "  '바다',\n",
       "  '여행',\n",
       "  '자연',\n",
       "  '몸',\n",
       "  '사랑',\n",
       "  'ᄀ',\n",
       "  '물',\n",
       "  '바닷가',\n",
       "  '재미',\n",
       "  '여름',\n",
       "  '모래',\n",
       "  '해',\n",
       "  '파도',\n",
       "  '시간',\n",
       "  '자유',\n",
       "  '남성']}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beach_keyword_token[0]  # 이게 뒤에 /NNG 있어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace를 하기 위함\n",
    "matched_df = pd.DataFrame(matched_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched_df shape\n",
    "# (10, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유니크한 index list를 구하기 위해 이중 리스트 flatten\n",
    "unique_index_list = list(set([y for x in matched_list for y in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unique_index in unique_index_list:\n",
    "    matched_df.replace(unique_index, poem_token[unique_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(image_token)):\n",
    "    matched_poem = matched_df.iloc[i].tolist() #i번째 image topic에 대해 매칭된 시\n",
    "    for poem_idx in range(len(matched_poem)):\n",
    "        image_tokens[i][poem_idx]['text'] = matched_poem[poem_idx]\n",
    "    with open('../data/final/{topic}.json'.format(topic=image_token[i]), 'w', encoding='utf-8') as f:\n",
    "        json.dump(image_tokens[i], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
